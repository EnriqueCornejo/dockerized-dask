{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Go to [localhost:8787][the workers' monitor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import xarray as xr\n",
    "import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from dask.dot import dot_graph\n",
    "import itertools\n",
    "import logging\n",
    "import netCDF4\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import dask.array as da\n",
    "from dask import delayed\n",
    "import time\n",
    "from dask.distributed import Client\n",
    "from urllib import request\n",
    "from multiprocessing import Pool\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# We define some important data\n",
    "client = Client('scheduler:8786')\n",
    "download_location = '/temp'\n",
    "data_url = 'http://nasanex.s3.amazonaws.com'\n",
    "# data_url = 'http://172.21.0.1:8080'\n",
    "max_download_attempts = 5\n",
    "all_models = ['ACCESS1-0',  'BNU-ESM', 'CCSM4', 'CESM1-BGC', 'CNRM-CM5', 'CSIRO-Mk3-6-0', 'CanESM2', 'GFDL-CM3', 'GFDL-ESM2G', 'GFDL-ESM2M', 'IPSL-CM5A-LR', 'IPSL-CM5A-MR', 'MIROC-ESM-CHEM', 'MIROC-ESM', 'MIROC5', 'MPI-ESM-LR', 'MPI-ESM-MR', 'MRI-CGCM3', 'NorESM1-M', 'bcc-csm1-1', 'inmcm4']\n",
    "all_models = ['ACCESS1-0',  'BNU-ESM']\n",
    "all_vars = ['tasmax', 'pr', 'tasmin']\n",
    "all_years = {\n",
    "    'historical': list(range(1971, 2001))\n",
    "}\n",
    "\n",
    "year_days = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "year_leap_days = [31, 29, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# And some functions to deal with loading data into the cluster\n",
    "def get_dataset_url(variable, scenario, model, year, prefix = data_url):\n",
    "    prefix_filename = '/'.join([prefix, 'NEX-GDDP', 'BCSD', scenario, 'day', 'atmos', variable, 'r1i1p1', 'v1.0'])\n",
    "    filename = '_'.join([variable, 'day', 'BCSD', scenario, 'r1i1p1', model, str(year) + '.nc'])\n",
    "    url = '/'.join([prefix_filename, filename])\n",
    "    # url = '/'.join([prefix, filename])\n",
    "    return url\n",
    "\n",
    "def get_context(year, **kwargs):\n",
    "    variables = [kwargs.get('variable')] if kwargs.get('variable') else all_vars\n",
    "    scenarios = ['historical']\n",
    "    models = [kwargs.get('model')] if kwargs.get('model') else all_models\n",
    "    outlist = []\n",
    "    combinations = list(itertools.product(variables, scenarios, models))\n",
    "    result = list(map(lambda comb: [ *comb, year ], combinations))\n",
    "    return result\n",
    "\n",
    "def get_year_ensemble(year, variable = 'tasmax'):\n",
    "    context = get_context(year, variable = variable)\n",
    "    datasets = list(map(lambda x: str(get_dataset_url(*x)), context))\n",
    "    return datasets\n",
    "\n",
    "def download_file(url):\n",
    "    print(\"url: \" + url)\n",
    "    attempts = 0\n",
    "    success = False\n",
    "    filename = \"\"\n",
    "    while attempts < max_download_attempts and not success:\n",
    "        time.sleep(2 ** attempts)\n",
    "        filename = '/'.join([download_location, str(url.split('/')[-1])])\n",
    "        print(\"Downloading file at \" + filename)\n",
    "        u = request.urlopen(url)\n",
    "        f = open(filename, 'wb')\n",
    "        f.write(u.read())\n",
    "        f.close()\n",
    "        success = True\n",
    "        break\n",
    "    return filename\n",
    "\n",
    "def download_file_list(url_list):\n",
    "    print(\"Starting download pool\")\n",
    "    pool = Pool()\n",
    "    res = pool.map(download_file, url_list)\n",
    "    print(\"Jobs sent\")\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    print(\"Downloads finished\")\n",
    "    print(res)\n",
    "    return res\n",
    "\n",
    "\n",
    "def download_and_stack(year):\n",
    "    tasmax_urls = list(map(lambda x: get_year_ensemble(x, variable = 'tasmax'), [year]))[0]\n",
    "    print(tasmax_urls)\n",
    "    tasmax_filenames = download_file_list(tasmax_urls)\n",
    "    print(tasmax_filenames)\n",
    "    tasmax_datasets = [ netCDF4.Dataset(filename) for filename in tasmax_filenames ]\n",
    "    print(tasmax_datasets)\n",
    "\n",
    "    tasmax_dask_arrays = []\n",
    "    for dset in tasmax_datasets:\n",
    "          tasmax_dask_arrays.append(da.from_array(dset['tasmax'], chunks= (366, 144, 144)))\n",
    "    try:\n",
    "          tasmax_final_stack = da.stack(tasmax_dask_arrays, axis = 0)\n",
    "          print(tasmax_final_stack)\n",
    "    except:\n",
    "        return tasmax_filenames, None, None\n",
    "\n",
    "    tasmin_urls = list(map(lambda x: get_year_ensemble(x, variable = 'tasmin'), [year]))[0]\n",
    "    print(tasmin_urls)\n",
    "    tasmin_filenames = download_file_list(tasmin_urls)\n",
    "    print(tasmin_filenames)\n",
    "    tasmin_datasets = [ netCDF4.Dataset(filename) for filename in tasmin_filenames ]\n",
    "    print(tasmin_datasets)\n",
    "\n",
    "    tasmin_dask_arrays = []\n",
    "    for dset in tasmin_datasets:\n",
    "          tasmin_dask_arrays.append(da.from_array(dset['tasmin'], chunks= (366, 144, 144)))\n",
    "    try:\n",
    "          tasmin_final_stack = da.stack(tasmin_dask_arrays, axis = 0)\n",
    "          print(tasmin_final_stack)\n",
    "    except:\n",
    "          return [*tasmax_filenames, *tasmin_filenames], None, None\n",
    "\n",
    "    final_stack = da.stack((tasmin_final_stack, tasmax_final_stack))\n",
    "    return [*tasmax_filenames, *tasmin_filenames], final_stack\n",
    "\n",
    "def destack(a, chunksize):\n",
    "    nmodels, tasvars, time, lat, lon = a.shape\n",
    "    nstacks_lat = int(np.ceil(lat / chunksize))\n",
    "    nstacks_lon = int(np.ceil(lon / chunksize))\n",
    "    \n",
    "    stacks = []\n",
    "    \n",
    "    for i in range(nstacks_lat):\n",
    "        for j in range(nstacks_lon):\n",
    "            latmin, latmax = i * chunksize, (i+1) * chunksize\n",
    "            lonmin, lonmax = j * chunksize, (j+1) * chunksize\n",
    "            # print(i, j, '~>', latmin, latmax, lonmin, lonmax)\n",
    "            stacked = a[:, :, :, latmin:latmax, lonmin:lonmax]\n",
    "            # print(stacked)\n",
    "            stacks.append(stacked)\n",
    "    return stacks\n",
    "\n",
    "def copy_dataset(src, output_filename):\n",
    "    dst = netCDF4.Dataset('/home/jovyan/work/' + output_filename, \"w\")\n",
    "    # copy attributes\n",
    "    for name in src.ncattrs():\n",
    "        dst.setncattr(name, src.getncattr(name))\n",
    "    # copy dimensions\n",
    "    for name, dimension in src.dimensions.items():\n",
    "        dst.createDimension(\n",
    "            name, (dimension)\n",
    "        )\n",
    "    dst.close()\n",
    "    return output_filename\n",
    "\n",
    "def restack(chunk_list, chunksize):\n",
    "    shapes = list(map(np.shape, chunk_list))\n",
    "    ndays = shapes[0][0]\n",
    "    nlons = int(1440 / chunksize)\n",
    "    nlats = int(720 / chunksize)\n",
    "    out_array = np.empty((ndays, 720, 1440))\n",
    "    combs = list(itertools.product(\n",
    "        list(range(nlats)),\n",
    "        list(range(nlons))\n",
    "    ))\n",
    "    res_list = zip(combs, chunk_list)\n",
    "    for position, arr in res_list:\n",
    "        minlon, maxlon = position[0] * chunksize, position[0] * chunksize + chunksize\n",
    "        minlat, maxlat = position[1] * chunksize, position[1] * chunksize + chunksize\n",
    "        out_array[:, minlon:maxlon, minlat:maxlat] = arr\n",
    "    return out_array\n",
    "\n",
    "def stack_from_disk(year, chunksize):\n",
    "    year_ensemble_tasmin = list(map(lambda x: x.split('/')[-1], get_year_ensemble(year, variable = 'tasmin')))\n",
    "    print(year_ensemble_tasmin)\n",
    "    year_ensemble_tasmax = list(map(lambda x: x.split('/')[-1], get_year_ensemble(year, variable = 'tasmax')))\n",
    "    print(year_ensemble_tasmax)\n",
    "    datasets_tasmin = [ netCDF4.Dataset('../temp/' + filename) for filename in year_ensemble_tasmin ]\n",
    "    print(datasets_tasmin)\n",
    "    datasets_tasmax = [ netCDF4.Dataset('../temp/' + filename) for filename in year_ensemble_tasmax ]\n",
    "    print(datasets_tasmax)\n",
    "    das_tasmin = list(map(lambda dset: da.from_array(dset['tasmin'], chunks = (365, chunksize, chunksize)), datasets_tasmin))\n",
    "    das_tasmax = list(map(lambda dset: da.from_array(dset['tasmax'], chunks = (365, chunksize, chunksize)), datasets_tasmax))\n",
    "    # da.stack(list(map(lambda dset: da.from_array(dset['tasmax'], chunks = (365, 144, 144)), datasets_tasmax)))\n",
    "    final_stack_tasmin = da.stack(das_tasmin)\n",
    "    final_stack_tasmax = da.stack(das_tasmax)\n",
    "    final_stack = da.stack(final_stack_tasmin, final_stack_tasmax)\n",
    "    return final_stack\n",
    "\n",
    "def days_to_ranges(years):\n",
    "    ranges = [year_days[:i +1] for i, n in enumerate(year_days)]\n",
    "    result = [(sum(element[:-1]), sum(element)) for element in ranges]\n",
    "    return result\n",
    "\n",
    "def stack_to_months(stack):\n",
    "    days = days_to_ranges(year_days) if stack.shape[2] == 365 else days_to_ranges(year_leap_days)\n",
    "    for period in days:\n",
    "        yield(stack[:, :, period[0]:period[1], :, :])\n",
    "\n",
    "def stack_to_models(stack):\n",
    "    for model in range(stack.shape[0]):\n",
    "        yield(stack[model, :, :, :])\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Ensure we have a clean client for testing\n",
    "client.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Load data to a dataset\n",
    "year = 1971\n",
    "\n",
    "print(f\"Starting processing for year {str(year)}\")\n",
    "print(datetime.datetime.now())\n",
    "print(\"Downloading\")\n",
    "\n",
    "# Stacking all data into the same dask dataset\n",
    "# Change for download from amazon\n",
    "stack_year = stack_from_disk(year, 144)\n",
    "# Geographic chunking\n",
    "print(stack_year)\n",
    "# dask.array<stack, shape=(21, 2, 365, 720, 1440), dtype=float32, chunksize=(1, 1, 365, 360, 360)>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# tasavg = np.mean(stack_year, axis = 1)\n",
    "# Can't really calc this without flooding memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Yearly indexes - we define the datasets as slices of the in-worker dataset\n",
    "tasmax_stack = stack_year[:, 0, :, :, :]\n",
    "tasmin_stack = stack_year[:, 1, :, :, :]\n",
    "\n",
    "print(tasmax_stack)\n",
    "print(tasmin_stack)\n",
    "\n",
    "tasavg_stack = (tasmax_stack + tasmin_stack) / 2\n",
    "print(tasavg_stack)\n",
    "\n",
    "tasmin_per_model = list(stack_to_models(tasmin_stack))\n",
    "tasmax_per_model = list(stack_to_models(tasmax_stack))\n",
    "tasavg_per_model = list(stack_to_models(tasavg_stack))\n",
    "print(tasavg_per_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Some test arrays for designing the indexes\n",
    "test_array_tasavg = tasavg_per_model[0].compute()\n",
    "test_array_tasmax = tasmax_per_model[0].compute()\n",
    "test_array_tasmin = tasmin_per_model[0].compute()\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# We load the temperature baseline from a numpy array in disk\n",
    "baseline = np.load('/temp/baseline_tasmax_99p.npy')\n",
    "client.scatter(baseline)\n",
    "\n",
    "# And define the functions to be applied over each dataset\n",
    "# This if for a single year, either one of the variables or the\n",
    "# tasavg stack, which would be calculated on-the-fly\n",
    "\n",
    "# Heating Degree Days - in C, transformation to F should not be problematic\n",
    "def hdd(a, axis):\n",
    "    a_to_baseline = 291.483 - a\n",
    "    masked = ma.masked_where(a_to_baseline <= 0, a_to_baseline)\n",
    "    intermediate_matrix = ma.filled(masked, fill_value = 0)\n",
    "    result = np.sum(intermediate_matrix, axis = 0)\n",
    "    return result\n",
    "\n",
    "# Cooling degree days\n",
    "def cdd(a, axis):\n",
    "    a_to_baseline = 291.483 - a\n",
    "    a_to_baseline[a_to_baseline < -10000] = 0\n",
    "    masked = ma.masked_where(a_to_baseline >= 0, a_to_baseline)\n",
    "    intermediate_matrix = ma.filled(masked, fill_value = 0)\n",
    "    result = np.sum(np.abs(intermediate_matrix), axis = 0)\n",
    "    return result\n",
    "\n",
    "# Number of days of the year with tasmax > 99 percentile from baseline 1971-2000\n",
    "def extreme_heat(a, axis):\n",
    "    a_to_baseline = a - baseline\n",
    "    masked = ma.masked_where(a_to_baseline <= 0, a_to_baseline)\n",
    "    intermediate_matrix = ma.filled(masked, fill_value = 0)\n",
    "    result = np.count_nonzero(intermediate_matrix, axis = axis)\n",
    "    return result\n",
    "\n",
    "# Helper function, not to be applied directly on the worker\n",
    "def longest_streak(diff):\n",
    "    result = 0\n",
    "    try:\n",
    "        result =  np.amax(\n",
    "            np.array(np.where(diff < 0)) - np.array(np.where(diff > 0))\n",
    "        )\n",
    "    except ValueError:\n",
    "        #raised if empty\n",
    "        result = 0\n",
    "    return result\n",
    "\n",
    "# Longest streak of days over freezing temperature (tasmin)\n",
    "def frost_free_season(a, axis):\n",
    "    # First, dealing with the first matrix\n",
    "    frost_days_matrix = (a > 273.15) * 1\n",
    "    # We pad it with zeroes at the ends of the designed axis\n",
    "    zeros_shape = list(a.shape)\n",
    "    del zeros_shape[axis]\n",
    "    zeros_matrix = np.expand_dims(np.zeros(zeros_shape), axis = axis)\n",
    "    concat_matrix = np.concatenate((zeros_matrix, frost_days_matrix, zeros_matrix))\n",
    "    # We calculate the deltas along an axis\n",
    "    diff = np.diff(concat_matrix, axis = axis)\n",
    "    # And get the longest streak from there --\n",
    "    # apply along axis is far from ideal, but\n",
    "    # np.where doesn't operate over axes, so we have to iterate\n",
    "    result = np.apply_along_axis(longest_streak, axis, diff)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "test_hdd_result = hdd(test_array_tasavg, axis = 0)\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(test_hdd_result, origin='lower')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "test_cdd_result = cdd(test_array_tasavg, axis = 0)\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(test_cdd_result, origin='lower')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "test_ff_result = frost_free_season(test_array_tasmin, axis = 0)\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(test_ff_result, origin='lower')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "test_xh_result = extreme_heat(test_array_tasmax, axis = 0)\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(test_xh_result, origin='lower')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "hdds_per_model = list(map(lambda arr: delayed(hdd)(arr, axis=0).compute(), tasavg_per_model))   \n",
    "hdds_final_stack = np.stack(hdds_per_model)\n",
    "hdds_final_result = np.stack((\n",
    "    np.mean(hdds_final_stack, axis = 0),\n",
    "    np.percentile(hdds_final_stack, q = 25, axis = 0),\n",
    "    np.percentile(hdds_final_stack, q = 75, axis = 0)\n",
    "))\n",
    "cdds_per_model = list(map(lambda arr: delayed(cdd)(arr, axis=0).compute(), tasavg_per_model))   \n",
    "cdds_final_stack = np.stack(cdds_per_model)\n",
    "cdds_final_result = np.stack((\n",
    "    np.mean(cdds_final_stack, axis = 0),\n",
    "    np.percentile(cdds_final_stack, q = 25, axis = 0),\n",
    "    np.percentile(cdds_final_stack, q = 75, axis = 0)\n",
    "))\n",
    "ffs_per_model = list(map(lambda arr: delayed(frost_free_season)(arr, axis=0).compute(), tasmin_per_model))\n",
    "ffs_final_stack = np.stack(ffs_per_model)\n",
    "ffs_final_result = np.stack((\n",
    "    np.mean(ffs_final_stack, axis = 0),\n",
    "    np.percentile(ffs_final_stack, q = 25, axis = 0),\n",
    "    np.percentile(ffs_final_stack, q = 75, axis = 0)\n",
    "))\n",
    "xs_per_model = list(map(lambda arr: delayed(extreme_heat)(arr, axis=0).compute(), tasmax_per_model))\n",
    "xs_final_stack = np.stack(xs_per_model)\n",
    "xs_final_result = np.stack((\n",
    "    np.mean(xs_final_stack, axis = 0),\n",
    "    np.percentile(xs_final_stack, q = 25, axis = 0),\n",
    "    np.percentile(xs_final_stack, q = 75, axis = 0)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "month_stacks = list(stack_to_months(stack_year))\n",
    "print(\"Processing monthly information\")\n",
    "for i, month in enumerate(month_stacks):\n",
    "    print(\"Processing month\")\n",
    "    # Processing temperatures\n",
    "    # Tasmin\n",
    "    tasmin_arr = month[:, 0, :, :, :]\n",
    "    # tasmin_arr.shape: (21, 31, 720, 1440)    \n",
    "    # In this case this axis corresponds to days\n",
    "    base_tasmin_mean = np.mean(tasmin_arr, axis = 1)\n",
    "    # So we first compute an average across days of the month, per mode\n",
    "    # And the mean and percentile per model\n",
    "    tasmin_avg = np.mean(base_tasmin_mean, axis = 0).compute()\n",
    "    tasmin_p75 = np.percentile(base_tasmin_mean, 75, axis = 0)\n",
    "    tasmin_p25 = np.percentile(base_tasmin_mean, 25, axis = 0)\n",
    "\n",
    "    tasmin_monthly_results = np.stack((\n",
    "        tasmin_avg,\n",
    "        tasmin_p25,\n",
    "        tasmin_p75\n",
    "    ))    \n",
    "    np.save(f\"/temp/tasmin_results_{year}_{i + 1}.npy\", tasmin_monthly_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "    # Tasmax\n",
    "    tasmax_arr = month[:, 1, :, :, :]\n",
    "    # print(f\"tasmax_arr.shape: {tasmax_arr.shape}\")\n",
    "\n",
    "    # base_tasmax_mean = np.mean(tasmax_arr, axis = 1)\n",
    "    # tasmax_avg = np.mean(base_tasmax_mean, axis = 0).compute()\n",
    "    # print(tasmax_avg.shape)\n",
    "    # tasmax_p75 = np.percentile(base_tasmax_mean, 75, axis = 0)\n",
    "    # print(tasmax_avg.shape)\n",
    "    # tasmax_p25 = np.percentile(base_tasmax_mean, 25, axis = 0)\n",
    "    # print(tasmax_avg.shape)\n",
    "\n",
    "    # tasavg_arr = (tasmin_arr + tasmax_arr) / 2\n",
    "    # print(tasavg_arr)\n",
    "    # base_tasavg_mean = np.mean(tasavg_arr, axis = 0)\n",
    "    # print(base_tasavg_mean)\n",
    "    # tasavg_avg = np.mean(base_tasavg_mean, axis = 0).compute()\n",
    "    # print(tasavg_avg.shape)\n",
    "    # tasavg_p75 = np.percentile(base_tasavg_mean, 75, axis = 0)\n",
    "    # print(tasavg_p75.shape)\n",
    "    # tasavg_p25 = np.percentile(base_tasavg_mean, 25, axis = 0)\n",
    "    # print(tasavg_p25.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tasmin_day_BCSD_historical_r1i1p1_ACCESS1-0_1971.nc', 'tasmin_day_BCSD_historical_r1i1p1_BNU-ESM_1971.nc']\n",
      "['tasmax_day_BCSD_historical_r1i1p1_ACCESS1-0_1971.nc', 'tasmax_day_BCSD_historical_r1i1p1_BNU-ESM_1971.nc']\n",
      "[<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4_CLASSIC data model, file format HDF5):\n",
      "    parent_experiment: pre-industrial control\n",
      "    parent_experiment_id: piControl\n",
      "    parent_experiment_rip: r1i1p1\n",
      "    Conventions: CF-1.4\n",
      "    institution: NASA Earth Exchange, NASA Ames Research Center, Moffett Field, CA 94035\n",
      "    institute_id: NASA-Ames\n",
      "    realm: atmos\n",
      "    modeling_realm: atmos\n",
      "    version: 1.0\n",
      "    downscalingModel: BCSD\n",
      "    experiment_id: historical\n",
      "    frequency: day\n",
      "    realization: 1\n",
      "    initialization_method: 1\n",
      "    physics_version: 1\n",
      "    tracking_id: 12f921d4-964f-43b9-b24e-0af265b13fec\n",
      "    driving_data_tracking_ids: N/A\n",
      "    driving_model_ensemble_member: r1i1p1\n",
      "    driving_experiment_name: pre-industrial control\n",
      "    driving_experiment: piControl\n",
      "    model_id: BCSD\n",
      "    references: BCSD method: Thrasher et al., 2012, Hydrol. Earth Syst. Sci.,16, 3309-3314. \n",
      "Ref period obs: latest version of the Princeton Global Meteorological Forcings (http://hydrology.princeton.edu/data.php), \n",
      "based on Sheffield et al., 2006, J. Climate, 19 (13), 3088-3111.\n",
      "    DOI: http://dx.doi.org/10.7292/W0MW2F2G\n",
      "    experiment: historical\n",
      "    title: ACCESS1-0 global downscaled NEX CMIP5 climate projection, r1i1p1\n",
      "    contact: Dr. Rama Nemani: rama.nemani@nasa.gov, Dr. Bridget Thrasher: bridget@climateanalyticsgroup.org\n",
      "    disclaimer: This data is considered provisional and subject to change. This data is provided as is without any warranty of any kind, either express or implied, arising by law or otherwise, including but not limited to warranties of completeness, non-infringement, accuracy, merchantability, or fitness for a particular purpose. The user assumes all risk associated with the use of, or inability to use, this data.\n",
      "    resolution_id: 0.25 degree\n",
      "    project_id: NEXGDDP\n",
      "    table_id: Table day (12 November 2010)\n",
      "    source: BCSD 2014\n",
      "    creation_date: 2015-01-07T19:08:53Z\n",
      "    forcing: N/A\n",
      "    product: output\n",
      "    dimensions(sizes): time(365), lat(720), lon(1440)\n",
      "    variables(dimensions): float64 \u001b[4mtime\u001b[0m(time), float32 \u001b[4mtasmin\u001b[0m(time,lat,lon), float32 \u001b[4mlat\u001b[0m(lat), float32 \u001b[4mlon\u001b[0m(lon)\n",
      "    groups: \n",
      ", <class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4_CLASSIC data model, file format HDF5):\n",
      "    parent_experiment: pre-industrial control\n",
      "    parent_experiment_id: piControl\n",
      "    parent_experiment_rip: r1i1p1\n",
      "    Conventions: CF-1.4\n",
      "    institution: NASA Earth Exchange, NASA Ames Research Center, Moffett Field, CA 94035\n",
      "    institute_id: NASA-Ames\n",
      "    realm: atmos\n",
      "    modeling_realm: atmos\n",
      "    version: 1.0\n",
      "    downscalingModel: BCSD\n",
      "    experiment_id: historical\n",
      "    frequency: day\n",
      "    realization: 1\n",
      "    initialization_method: 1\n",
      "    physics_version: 1\n",
      "    tracking_id: 19231aba-26fe-4ad1-9d24-ece75d76ff43\n",
      "    driving_data_tracking_ids: N/A\n",
      "    driving_model_ensemble_member: r1i1p1\n",
      "    driving_experiment_name: pre-industrial control\n",
      "    driving_experiment: piControl\n",
      "    model_id: BCSD\n",
      "    references: BCSD method: Thrasher et al., 2012, Hydrol. Earth Syst. Sci.,16, 3309-3314. \n",
      "Ref period obs: latest version of the Princeton Global Meteorological Forcings (http://hydrology.princeton.edu/data.php), \n",
      "based on Sheffield et al., 2006, J. Climate, 19 (13), 3088-3111.\n",
      "    DOI: http://dx.doi.org/10.7292/W0MW2F2G\n",
      "    experiment: historical\n",
      "    title: BNU-ESM global downscaled NEX CMIP5 climate projection, r1i1p1\n",
      "    contact: Dr. Rama Nemani: rama.nemani@nasa.gov, Dr. Bridget Thrasher: bridget@climateanalyticsgroup.org\n",
      "    disclaimer: This data is considered provisional and subject to change. This data is provided as is without any warranty of any kind, either express or implied, arising by law or otherwise, including but not limited to warranties of completeness, non-infringement, accuracy, merchantability, or fitness for a particular purpose. The user assumes all risk associated with the use of, or inability to use, this data.\n",
      "    resolution_id: 0.25 degree\n",
      "    project_id: NEXGDDP\n",
      "    table_id: Table day (12 November 2010)\n",
      "    source: BCSD 2014\n",
      "    creation_date: 2015-01-07T19:12:25Z\n",
      "    forcing: N/A\n",
      "    product: output\n",
      "    dimensions(sizes): time(365), lat(720), lon(1440)\n",
      "    variables(dimensions): float64 \u001b[4mtime\u001b[0m(time), float32 \u001b[4mtasmin\u001b[0m(time,lat,lon), float32 \u001b[4mlat\u001b[0m(lat), float32 \u001b[4mlon\u001b[0m(lon)\n",
      "    groups: \n",
      "]\n",
      "[<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4_CLASSIC data model, file format HDF5):\n",
      "    parent_experiment: pre-industrial control\n",
      "    parent_experiment_id: piControl\n",
      "    parent_experiment_rip: r1i1p1\n",
      "    Conventions: CF-1.4\n",
      "    institution: NASA Earth Exchange, NASA Ames Research Center, Moffett Field, CA 94035\n",
      "    institute_id: NASA-Ames\n",
      "    realm: atmos\n",
      "    modeling_realm: atmos\n",
      "    version: 1.0\n",
      "    downscalingModel: BCSD\n",
      "    experiment_id: historical\n",
      "    frequency: day\n",
      "    realization: 1\n",
      "    initialization_method: 1\n",
      "    physics_version: 1\n",
      "    tracking_id: a03ef829-f7dd-4474-bb39-c24e24520a12\n",
      "    driving_data_tracking_ids: N/A\n",
      "    driving_model_ensemble_member: r1i1p1\n",
      "    driving_experiment_name: pre-industrial control\n",
      "    driving_experiment: piControl\n",
      "    model_id: BCSD\n",
      "    references: BCSD method: Thrasher et al., 2012, Hydrol. Earth Syst. Sci.,16, 3309-3314. \n",
      "Ref period obs: latest version of the Princeton Global Meteorological Forcings (http://hydrology.princeton.edu/data.php), \n",
      "based on Sheffield et al., 2006, J. Climate, 19 (13), 3088-3111.\n",
      "    DOI: http://dx.doi.org/10.7292/W0MW2F2G\n",
      "    experiment: historical\n",
      "    title: ACCESS1-0 global downscaled NEX CMIP5 climate projection, r1i1p1\n",
      "    contact: Dr. Rama Nemani: rama.nemani@nasa.gov, Dr. Bridget Thrasher: bridget@climateanalyticsgroup.org\n",
      "    disclaimer: This data is considered provisional and subject to change. This data is provided as is without any warranty of any kind, either express or implied, arising by law or otherwise, including but not limited to warranties of completeness, non-infringement, accuracy, merchantability, or fitness for a particular purpose. The user assumes all risk associated with the use of, or inability to use, this data.\n",
      "    resolution_id: 0.25 degree\n",
      "    project_id: NEXGDDP\n",
      "    table_id: Table day (12 November 2010)\n",
      "    source: BCSD 2014\n",
      "    creation_date: 2015-01-07T20:15:24Z\n",
      "    forcing: N/A\n",
      "    product: output\n",
      "    dimensions(sizes): time(365), lat(720), lon(1440)\n",
      "    variables(dimensions): float64 \u001b[4mtime\u001b[0m(time), float32 \u001b[4mtasmax\u001b[0m(time,lat,lon), float32 \u001b[4mlat\u001b[0m(lat), float32 \u001b[4mlon\u001b[0m(lon)\n",
      "    groups: \n",
      ", <class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4_CLASSIC data model, file format HDF5):\n",
      "    parent_experiment: pre-industrial control\n",
      "    parent_experiment_id: piControl\n",
      "    parent_experiment_rip: r1i1p1\n",
      "    Conventions: CF-1.4\n",
      "    institution: NASA Earth Exchange, NASA Ames Research Center, Moffett Field, CA 94035\n",
      "    institute_id: NASA-Ames\n",
      "    realm: atmos\n",
      "    modeling_realm: atmos\n",
      "    version: 1.0\n",
      "    downscalingModel: BCSD\n",
      "    experiment_id: historical\n",
      "    frequency: day\n",
      "    realization: 1\n",
      "    initialization_method: 1\n",
      "    physics_version: 1\n",
      "    tracking_id: fda08a98-e156-46b2-bba4-c5c8d4d3a286\n",
      "    driving_data_tracking_ids: N/A\n",
      "    driving_model_ensemble_member: r1i1p1\n",
      "    driving_experiment_name: pre-industrial control\n",
      "    driving_experiment: piControl\n",
      "    model_id: BCSD\n",
      "    references: BCSD method: Thrasher et al., 2012, Hydrol. Earth Syst. Sci.,16, 3309-3314. \n",
      "Ref period obs: latest version of the Princeton Global Meteorological Forcings (http://hydrology.princeton.edu/data.php), \n",
      "based on Sheffield et al., 2006, J. Climate, 19 (13), 3088-3111.\n",
      "    DOI: http://dx.doi.org/10.7292/W0MW2F2G\n",
      "    experiment: historical\n",
      "    title: BNU-ESM global downscaled NEX CMIP5 climate projection, r1i1p1\n",
      "    contact: Dr. Rama Nemani: rama.nemani@nasa.gov, Dr. Bridget Thrasher: bridget@climateanalyticsgroup.org\n",
      "    disclaimer: This data is considered provisional and subject to change. This data is provided as is without any warranty of any kind, either express or implied, arising by law or otherwise, including but not limited to warranties of completeness, non-infringement, accuracy, merchantability, or fitness for a particular purpose. The user assumes all risk associated with the use of, or inability to use, this data.\n",
      "    resolution_id: 0.25 degree\n",
      "    project_id: NEXGDDP\n",
      "    table_id: Table day (12 November 2010)\n",
      "    source: BCSD 2014\n",
      "    creation_date: 2015-01-07T20:18:20Z\n",
      "    forcing: N/A\n",
      "    product: output\n",
      "    dimensions(sizes): time(365), lat(720), lon(1440)\n",
      "    variables(dimensions): float64 \u001b[4mtime\u001b[0m(time), float32 \u001b[4mtasmax\u001b[0m(time,lat,lon), float32 \u001b[4mlat\u001b[0m(lat), float32 \u001b[4mlon\u001b[0m(lon)\n",
      "    groups: \n",
      "]\n"
     ]
    }
   ],
   "source": [
    "for year in all_years['historical']:\n",
    "    # stack_year = download_and_stack(year)\n",
    "    stack_year = stack_from_disk(year, 360)\n",
    "    print(stack_year)\n",
    "    tasmax_stack = stack_year[0, :, :, :, :]\n",
    "    tasmin_stack = stack_year[1, :, :, :, :]\n",
    "    tasavg_stack = (tasmax_stack + tasmin_stack) / 2\n",
    "    tasmin_per_model = list(stack_to_models(tasmin_stack))\n",
    "    tasmax_per_model = list(stack_to_models(tasmax_stack))\n",
    "    tasavg_per_model = list(stack_to_models(tasavg_stack))\n",
    "\n",
    "    baseline = np.load('/temp/baseline_tasmax_99p.npy')\n",
    "    client.scatter(baseline)\n",
    "\n",
    "    hdds_per_model = list(map(lambda arr: delayed(hdd)(arr, axis=0).compute(), tasavg_per_model))   \n",
    "    hdds_final_stack = np.stack(hdds_per_model)\n",
    "    hdds_final_result = np.stack((\n",
    "        np.mean(hdds_final_stack, axis = 0),\n",
    "        np.percentile(hdds_final_stack, q = 25, axis = 0),\n",
    "        np.percentile(hdds_final_stack, q = 75, axis = 0)\n",
    "    ))\n",
    "    cdds_per_model = list(map(lambda arr: delayed(cdd)(arr, axis=0).compute(), tasavg_per_model))   \n",
    "    cdds_final_stack = np.stack(cdds_per_model)\n",
    "    cdds_final_result = np.stack((\n",
    "        np.mean(cdds_final_stack, axis = 0),\n",
    "        np.percentile(cdds_final_stack, q = 25, axis = 0),\n",
    "        np.percentile(cdds_final_stack, q = 75, axis = 0)\n",
    "    ))\n",
    "    ffs_per_model = list(map(lambda arr: delayed(frost_free_season)(arr, axis=0).compute(), tasmin_per_model))\n",
    "    ffs_final_stack = np.stack(ffs_per_model)\n",
    "    ffs_final_result = np.stack((\n",
    "        np.mean(ffs_final_stack, axis = 0),\n",
    "        np.percentile(ffs_final_stack, q = 25, axis = 0),\n",
    "        np.percentile(ffs_final_stack, q = 75, axis = 0)\n",
    "    ))\n",
    "    xs_per_model = list(map(lambda arr: delayed(extreme_heat)(arr, axis=0).compute(), tasmax_per_model))\n",
    "    xs_final_stack = np.stack(xs_per_model)\n",
    "    xs_final_result = np.stack((\n",
    "        np.mean(xs_final_stack, axis = 0),\n",
    "        np.percentile(xs_final_stack, q = 25, axis = 0),\n",
    "        np.percentile(xs_final_stack, q = 75, axis = 0)\n",
    "    ))\n",
    "\n",
    "    totals = np.stack((hdds_per_model, cdds_per_model, ffs_per_model, xs_per_model))\n",
    "    \n",
    "    numpy.save(f\"/temp/{year}_annual_temperature_measures.npy\", totals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline_tasmax_99p.npy\r\n",
      "maskedhddarrtest.npy\r\n",
      "tasmax_day_BCSD_historical_r1i1p1_ACCESS1-0_1971.nc\r\n",
      "tasmax_day_BCSD_historical_r1i1p1_bcc-csm1-1_1971.nc\r\n",
      "tasmax_day_BCSD_historical_r1i1p1_BNU-ESM_1971.nc\r\n",
      "tasmax_day_BCSD_historical_r1i1p1_CanESM2_1971.nc\r\n",
      "tasmax_day_BCSD_historical_r1i1p1_CCSM4_1971.nc\r\n",
      "tasmax_day_BCSD_historical_r1i1p1_CESM1-BGC_1971.nc\r\n",
      "tasmax_day_BCSD_historical_r1i1p1_CNRM-CM5_1971.nc\r\n",
      "tasmax_day_BCSD_historical_r1i1p1_CSIRO-Mk3-6-0_1971.nc\r\n",
      "tasmax_day_BCSD_historical_r1i1p1_GFDL-CM3_1971.nc\r\n",
      "tasmax_day_BCSD_historical_r1i1p1_GFDL-ESM2G_1971.nc\r\n",
      "tasmax_day_BCSD_historical_r1i1p1_GFDL-ESM2M_1971.nc\r\n",
      "tasmax_day_BCSD_historical_r1i1p1_inmcm4_1971.nc\r\n",
      "tasmax_day_BCSD_historical_r1i1p1_IPSL-CM5A-LR_1971.nc\r\n",
      "tasmax_day_BCSD_historical_r1i1p1_IPSL-CM5A-MR_1971.nc\r\n",
      "tasmax_day_BCSD_historical_r1i1p1_MIROC5_1971.nc\r\n",
      "tasmax_day_BCSD_historical_r1i1p1_MIROC-ESM_1971.nc\r\n",
      "tasmax_day_BCSD_historical_r1i1p1_MIROC-ESM-CHEM_1971.nc\r\n",
      "tasmax_day_BCSD_historical_r1i1p1_MPI-ESM-LR_1971.nc\r\n",
      "tasmax_day_BCSD_historical_r1i1p1_MPI-ESM-MR_1971.nc\r\n",
      "tasmax_day_BCSD_historical_r1i1p1_MRI-CGCM3_1971.nc\r\n",
      "tasmax_day_BCSD_historical_r1i1p1_NorESM1-M_1971.nc\r\n",
      "tasmin_day_BCSD_historical_r1i1p1_ACCESS1-0_1971.nc\r\n",
      "tasmin_day_BCSD_historical_r1i1p1_bcc-csm1-1_1971.nc\r\n",
      "tasmin_day_BCSD_historical_r1i1p1_BNU-ESM_1971.nc\r\n",
      "tasmin_day_BCSD_historical_r1i1p1_CanESM2_1971.nc\r\n",
      "tasmin_day_BCSD_historical_r1i1p1_CCSM4_1971.nc\r\n",
      "tasmin_day_BCSD_historical_r1i1p1_CESM1-BGC_1971.nc\r\n",
      "tasmin_day_BCSD_historical_r1i1p1_CNRM-CM5_1971.nc\r\n",
      "tasmin_day_BCSD_historical_r1i1p1_CSIRO-Mk3-6-0_1971.nc\r\n",
      "tasmin_day_BCSD_historical_r1i1p1_GFDL-CM3_1971.nc\r\n",
      "tasmin_day_BCSD_historical_r1i1p1_GFDL-ESM2G_1971.nc\r\n",
      "tasmin_day_BCSD_historical_r1i1p1_GFDL-ESM2M_1971.nc\r\n",
      "tasmin_day_BCSD_historical_r1i1p1_inmcm4_1971.nc\r\n",
      "tasmin_day_BCSD_historical_r1i1p1_IPSL-CM5A-LR_1971.nc\r\n",
      "tasmin_day_BCSD_historical_r1i1p1_IPSL-CM5A-MR_1971.nc\r\n",
      "tasmin_day_BCSD_historical_r1i1p1_MIROC5_1971.nc\r\n",
      "tasmin_day_BCSD_historical_r1i1p1_MIROC-ESM_1971.nc\r\n",
      "tasmin_day_BCSD_historical_r1i1p1_MIROC-ESM-CHEM_1971.nc\r\n",
      "tasmin_day_BCSD_historical_r1i1p1_MPI-ESM-LR_1971.nc\r\n",
      "tasmin_day_BCSD_historical_r1i1p1_MPI-ESM-MR_1971.nc\r\n",
      "tasmin_day_BCSD_historical_r1i1p1_MRI-CGCM3_1971.nc\r\n",
      "tasmin_day_BCSD_historical_r1i1p1_NorESM1-M_1971.nc\r\n",
      "tasmin_results_1971_1.npy\r\n"
     ]
    }
   ],
   "source": [
    "ls ../temp/tasmax_day_BCSD_historical_r1i1p1_BNU-ESM_1971.nc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "name": "process_temperatures.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
