{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://scheduler:8786\n",
       "  <li><b>Dashboard: </b><a href='http://scheduler:8787' target='_blank'>http://scheduler:8787</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>16.81 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://172.21.0.4:8786' processes=1 cores=4>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from dask.dot import dot_graph\n",
    "import itertools\n",
    "import logging\n",
    "import netCDF4\n",
    "import numpy as np\n",
    "import dask.array as da\n",
    "from dask import delayed\n",
    "import time\n",
    "from dask.distributed import Client\n",
    "from urllib import request\n",
    "from multiprocessing import Pool\n",
    "\n",
    "client = Client('scheduler:8786')\n",
    "\n",
    "download_location = '/temp'\n",
    "data_url = 'http://nasanex.s3.amazonaws.com'\n",
    "# data_url = 'http://172.21.0.1:8080'\n",
    "max_download_attempts = 5\n",
    "\n",
    "all_models = ['ACCESS1-0',  'BNU-ESM', 'CCSM4', 'CESM1-BGC', 'CNRM-CM5', 'CSIRO-Mk3-6-0', 'CanESM2', 'GFDL-CM3', 'GFDL-ESM2G', 'GFDL-ESM2M', 'IPSL-CM5A-LR', 'IPSL-CM5A-MR', 'MIROC-ESM-CHEM', 'MIROC-ESM', 'MIROC5', 'MPI-ESM-LR', 'MPI-ESM-MR', 'MRI-CGCM3', 'NorESM1-M', 'bcc-csm1-1', 'inmcm4']\n",
    "# all_models = ['ACCESS1-0', 'BNU-ESM'] \n",
    "all_vars = ['tasmax', 'pr']\n",
    "all_years = {\n",
    "     # 'historical': list(range(1971, 1976))\n",
    "    'historical': list(range(1971, 2001))\n",
    "}\n",
    "\n",
    "def get_dataset_url(variable, scenario, model, year, prefix = data_url):\n",
    "    prefix_filename = '/'.join([prefix, 'NEX-GDDP', 'BCSD', scenario, 'day', 'atmos', variable, 'r1i1p1', 'v1.0'])\n",
    "    filename = '_'.join([variable, 'day', 'BCSD', scenario, 'r1i1p1', model, str(year) + '.nc'])\n",
    "    url = '/'.join([prefix_filename, filename])\n",
    "    return url\n",
    "\n",
    "def get_context(year, **kwargs):\n",
    "    variables = [kwargs.get('variable')] if kwargs.get('variable') else all_vars\n",
    "    scenarios = ['historical']\n",
    "    models = [kwargs.get('model')] if kwargs.get('model') else all_models\n",
    "    outlist = []\n",
    "    combinations = list(itertools.product(variables, scenarios, models))\n",
    "    result = list(map(lambda comb: [ *comb, year ], combinations))\n",
    "    return result\n",
    "\n",
    "def get_year_ensemble(year, variable = 'tasmax'):\n",
    "    context = get_context(year, variable = variable)\n",
    "    datasets = list(map(lambda x: str(get_dataset_url(*x)), context))\n",
    "    return datasets\n",
    "\n",
    "def download_file(url):\n",
    "    print(\"url: \" + url)\n",
    "    attempts = 0\n",
    "    success = False\n",
    "    filename = \"\"\n",
    "    while attempts < max_download_attempts and not success:\n",
    "        time.sleep(2 ** attempts)\n",
    "        filename = '/'.join([download_location, str(url.split('/')[-1])])\n",
    "        print(\"Downloading file at \" + filename)\n",
    "        u = request.urlopen(url)\n",
    "        f = open(filename, 'wb')\n",
    "        f.write(u.read())\n",
    "        f.close()\n",
    "        success = True\n",
    "        break\n",
    "    return filename\n",
    "\n",
    "def download_file_list(url_list):\n",
    "    print(\"Starting download pool\")\n",
    "    pool = Pool()\n",
    "    res = pool.map(download_file, url_list)\n",
    "    print(\"Jobs sent\")\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    print(\"Downloads finished\")\n",
    "    print(res)\n",
    "    return res\n",
    "\n",
    "def download_and_stack(year, variable):\n",
    "    dsets_urls = list(map(lambda x: get_year_ensemble(x, variable = variable), [year]))[0]\n",
    "    filenames = download_file_list(dsets_urls)\n",
    "    datasets = [ netCDF4.Dataset(filename) for filename in filenames ]\n",
    "    dask_arrays = []\n",
    "    for dset in datasets:\n",
    "        dask_arrays.append(da.from_array(dset[str(variable)], chunks= (366, 144, 144)))\n",
    "    try:\n",
    "        final_stack = da.stack(dask_arrays, axis = 0)\n",
    "    except:\n",
    "        return filenames, None, None\n",
    "    return filenames, datasets, final_stack\n",
    "\n",
    "def get_stacks_mod_avg(a, chunksize):\n",
    "    nmodels, time, lat, lon = a.shape\n",
    "    nstacks_lat = int(np.ceil(lat / chunksize))\n",
    "    nstacks_lon = int(np.ceil(lon / chunksize))\n",
    "    \n",
    "    stacks = []\n",
    "    \n",
    "    for i in range(nstacks_lat):\n",
    "        for j in range(nstacks_lon):\n",
    "            latmin, latmax = i * chunksize, (i+1) * chunksize\n",
    "            lonmin, lonmax = j * chunksize, (j+1) * chunksize\n",
    "            print(i, j, '~>', latmin, latmax, lonmin, lonmax)\n",
    "            stacked = a[:, :, latmin:latmax, lonmin:lonmax]\n",
    "            print(stacked)\n",
    "            stacks.append(stacked)\n",
    "    return stacks\n",
    "\n",
    "def copy_dataset(src, output_filename):\n",
    "    dst = netCDF4.Dataset('/home/jovyan/work/' + output_filename, \"w\")\n",
    "    # copy attributes\n",
    "    for name in src.ncattrs():\n",
    "        dst.setncattr(name, src.getncattr(name))\n",
    "    # copy dimensions\n",
    "    for name, dimension in src.dimensions.items():\n",
    "        dst.createDimension(\n",
    "            name, (dimension)\n",
    "        )\n",
    "    dst.close()\n",
    "    return output_filename\n",
    "\n",
    "def restack(chunk_list, chunksize):\n",
    "    shapes = list(map(np.shape, chunk_list))\n",
    "    ndays = shapes[0][0]\n",
    "    nlons = int(1440 / chunksize)\n",
    "    nlats = int(720 / chunksize)\n",
    "    out_array = np.empty((ndays, 720, 1440))\n",
    "    combs = list(itertools.product(\n",
    "        list(range(nlats)),\n",
    "        list(range(nlons))\n",
    "    ))\n",
    "    res_list = zip(combs, chunk_list)\n",
    "    for position, arr in res_list:\n",
    "        minlon, maxlon = position[0] * chunksize, position[0] * chunksize + chunksize\n",
    "        minlat, maxlat = position[1] * chunksize, position[1] * chunksize + chunksize\n",
    "        out_array[:, minlon:maxlon, minlat:maxlat] = arr\n",
    "    return out_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download pool\n",
      "url: http://nasanex.s3.amazonaws.com/NEX-GDDP/BCSD/historical/day/atmos/tasmax/r1i1p1/v1.0/tasmax_day_BCSD_historical_r1i1p1_ACCESS1-0_1971.nc\n",
      "url: http://nasanex.s3.amazonaws.com/NEX-GDDP/BCSD/historical/day/atmos/tasmax/r1i1p1/v1.0/tasmax_day_BCSD_historical_r1i1p1_BNU-ESM_1971.nc\n",
      "Downloading file at /temp/tasmax_day_BCSD_historical_r1i1p1_ACCESS1-0_1971.nc\n",
      "Downloading file at /temp/tasmax_day_BCSD_historical_r1i1p1_BNU-ESM_1971.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-6:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-5:\n",
      "  File \"/opt/conda/envs/dask/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/dask/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/dask/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/dask/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/envs/dask/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/dask/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/dask/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/conda/envs/dask/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"<ipython-input-6-52bfa8dbf479>\", line 63, in download_file\n",
      "    f.write(u.read())\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/dask/lib/python3.6/http/client.py\", line 462, in read\n",
      "    s = self._safe_read(self.length)\n",
      "  File \"/opt/conda/envs/dask/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/dask/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/dask/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/dask/lib/python3.6/http/client.py\", line 612, in _safe_read\n",
      "    chunk = self.fp.read(min(amt, MAXAMOUNT))\n",
      "  File \"/opt/conda/envs/dask/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/conda/envs/dask/lib/python3.6/socket.py\", line 586, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/dask/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"<ipython-input-6-52bfa8dbf479>\", line 63, in download_file\n",
      "    f.write(u.read())\n",
      "  File \"/opt/conda/envs/dask/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/dask/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/envs/dask/lib/python3.6/http/client.py\", line 462, in read\n",
      "    s = self._safe_read(self.length)\n",
      "  File \"/opt/conda/envs/dask/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/dask/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/envs/dask/lib/python3.6/http/client.py\", line 612, in _safe_read\n",
      "    chunk = self.fp.read(min(amt, MAXAMOUNT))\n",
      "  File \"/opt/conda/envs/dask/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/dask/lib/python3.6/socket.py\", line 586, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/dask/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/dask/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-26de03938bc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'tasmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tasmin'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myears\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtasmax_filenames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasmax_datasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasmax_current_year_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_and_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtasmin_filenames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasmin_datasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasmin_current_year_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_and_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasmax_current_year_stack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-52bfa8dbf479>\u001b[0m in \u001b[0;36mdownload_and_stack\u001b[0;34m(year, variable)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdownload_and_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mdsets_urls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_year_ensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_file_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsets_urls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mnetCDF4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilenames\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mdask_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-52bfa8dbf479>\u001b[0m in \u001b[0;36mdownload_file_list\u001b[0;34m(url_list)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting download pool\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Jobs sent\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/dask/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         '''\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/dask/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/dask/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/dask/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/dask/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Processing tas yearly\n",
    "years = list(range(1971, 1972))\n",
    "vars = ['tasmax', 'tasmin']\n",
    "for i, year in enumerate(years):\n",
    "    tasmax_filenames, tasmax_datasets, tasmax_current_year_stack = download_and_stack(year, variable=vars[0])\n",
    "    tasmin_filenames, tasmin_datasets, tasmin_current_year_stack = download_and_stack(year, variable=vars[1])\n",
    "    print(tasmax_current_year_stack)\n",
    "    print(tasmin_current_year_stack)\n",
    "    \n",
    "    \n",
    "    # Finally\n",
    "    for filename in [*tasmax_filenames, *tasmin_filenames]:\n",
    "        os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1971"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = 1971\n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download pool\n",
      "url: http://nasanex.s3.amazonaws.com/NEX-GDDP/BCSD/historical/day/atmos/tasmax/r1i1p1/v1.0/tasmax_day_BCSD_historical_r1i1p1_ACCESS1-0_1971.nc\n",
      "url: http://nasanex.s3.amazonaws.com/NEX-GDDP/BCSD/historical/day/atmos/tasmax/r1i1p1/v1.0/tasmax_day_BCSD_historical_r1i1p1_CCSM4_1971.nc\n",
      "url: http://nasanex.s3.amazonaws.com/NEX-GDDP/BCSD/historical/day/atmos/tasmax/r1i1p1/v1.0/tasmax_day_BCSD_historical_r1i1p1_CanESM2_1971.nc\n",
      "url: http://nasanex.s3.amazonaws.com/NEX-GDDP/BCSD/historical/day/atmos/tasmax/r1i1p1/v1.0/tasmax_day_BCSD_historical_r1i1p1_CNRM-CM5_1971.nc\n",
      "Downloading file at /temp/tasmax_day_BCSD_historical_r1i1p1_CCSM4_1971.nc\n",
      "Downloading file at /temp/tasmax_day_BCSD_historical_r1i1p1_CanESM2_1971.nc\n",
      "Downloading file at /temp/tasmax_day_BCSD_historical_r1i1p1_CNRM-CM5_1971.nc\n",
      "Downloading file at /temp/tasmax_day_BCSD_historical_r1i1p1_ACCESS1-0_1971.nc\n",
      "url: http://nasanex.s3.amazonaws.com/NEX-GDDP/BCSD/historical/day/atmos/tasmax/r1i1p1/v1.0/tasmax_day_BCSD_historical_r1i1p1_GFDL-CM3_1971.nc\n",
      "Downloading file at /temp/tasmax_day_BCSD_historical_r1i1p1_GFDL-CM3_1971.nc\n",
      "url: http://nasanex.s3.amazonaws.com/NEX-GDDP/BCSD/historical/day/atmos/tasmax/r1i1p1/v1.0/tasmax_day_BCSD_historical_r1i1p1_CSIRO-Mk3-6-0_1971.nc\n",
      "Downloading file at /temp/tasmax_day_BCSD_historical_r1i1p1_CSIRO-Mk3-6-0_1971.nc\n",
      "url: http://nasanex.s3.amazonaws.com/NEX-GDDP/BCSD/historical/day/atmos/tasmax/r1i1p1/v1.0/tasmax_day_BCSD_historical_r1i1p1_BNU-ESM_1971.nc\n",
      "Downloading file at /temp/tasmax_day_BCSD_historical_r1i1p1_BNU-ESM_1971.nc\n",
      "url: http://nasanex.s3.amazonaws.com/NEX-GDDP/BCSD/historical/day/atmos/tasmax/r1i1p1/v1.0/tasmax_day_BCSD_historical_r1i1p1_CESM1-BGC_1971.nc\n",
      "Downloading file at /temp/tasmax_day_BCSD_historical_r1i1p1_CESM1-BGC_1971.nc\n",
      "url: http://nasanex.s3.amazonaws.com/NEX-GDDP/BCSD/historical/day/atmos/tasmax/r1i1p1/v1.0/tasmax_day_BCSD_historical_r1i1p1_GFDL-ESM2G_1971.nc\n",
      "Downloading file at /temp/tasmax_day_BCSD_historical_r1i1p1_GFDL-ESM2G_1971.nc\n",
      "url: http://nasanex.s3.amazonaws.com/NEX-GDDP/BCSD/historical/day/atmos/tasmax/r1i1p1/v1.0/tasmax_day_BCSD_historical_r1i1p1_IPSL-CM5A-LR_1971.nc\n",
      "Downloading file at /temp/tasmax_day_BCSD_historical_r1i1p1_IPSL-CM5A-LR_1971.nc\n",
      "url: http://nasanex.s3.amazonaws.com/NEX-GDDP/BCSD/historical/day/atmos/tasmax/r1i1p1/v1.0/tasmax_day_BCSD_historical_r1i1p1_MIROC-ESM-CHEM_1971.nc\n",
      "Downloading file at /temp/tasmax_day_BCSD_historical_r1i1p1_MIROC-ESM-CHEM_1971.nc\n",
      "url: http://nasanex.s3.amazonaws.com/NEX-GDDP/BCSD/historical/day/atmos/tasmax/r1i1p1/v1.0/tasmax_day_BCSD_historical_r1i1p1_MIROC5_1971.nc\n",
      "Downloading file at /temp/tasmax_day_BCSD_historical_r1i1p1_MIROC5_1971.nc\n",
      "url: http://nasanex.s3.amazonaws.com/NEX-GDDP/BCSD/historical/day/atmos/tasmax/r1i1p1/v1.0/tasmax_day_BCSD_historical_r1i1p1_IPSL-CM5A-MR_1971.nc\n",
      "Downloading file at /temp/tasmax_day_BCSD_historical_r1i1p1_IPSL-CM5A-MR_1971.nc\n",
      "url: http://nasanex.s3.amazonaws.com/NEX-GDDP/BCSD/historical/day/atmos/tasmax/r1i1p1/v1.0/tasmax_day_BCSD_historical_r1i1p1_MIROC-ESM_1971.nc\n",
      "Downloading file at /temp/tasmax_day_BCSD_historical_r1i1p1_MIROC-ESM_1971.nc\n",
      "url: http://nasanex.s3.amazonaws.com/NEX-GDDP/BCSD/historical/day/atmos/tasmax/r1i1p1/v1.0/tasmax_day_BCSD_historical_r1i1p1_MPI-ESM-LR_1971.nc\n",
      "Downloading file at /temp/tasmax_day_BCSD_historical_r1i1p1_MPI-ESM-LR_1971.nc\n",
      "url: http://nasanex.s3.amazonaws.com/NEX-GDDP/BCSD/historical/day/atmos/tasmax/r1i1p1/v1.0/tasmax_day_BCSD_historical_r1i1p1_GFDL-ESM2M_1971.nc\n",
      "Downloading file at /temp/tasmax_day_BCSD_historical_r1i1p1_GFDL-ESM2M_1971.nc\n",
      "url: http://nasanex.s3.amazonaws.com/NEX-GDDP/BCSD/historical/day/atmos/tasmax/r1i1p1/v1.0/tasmax_day_BCSD_historical_r1i1p1_MPI-ESM-MR_1971.nc\n",
      "Downloading file at /temp/tasmax_day_BCSD_historical_r1i1p1_MPI-ESM-MR_1971.nc\n",
      "url: http://nasanex.s3.amazonaws.com/NEX-GDDP/BCSD/historical/day/atmos/tasmax/r1i1p1/v1.0/tasmax_day_BCSD_historical_r1i1p1_NorESM1-M_1971.nc\n",
      "Downloading file at /temp/tasmax_day_BCSD_historical_r1i1p1_NorESM1-M_1971.nc\n",
      "url: http://nasanex.s3.amazonaws.com/NEX-GDDP/BCSD/historical/day/atmos/tasmax/r1i1p1/v1.0/tasmax_day_BCSD_historical_r1i1p1_inmcm4_1971.nc\n",
      "Downloading file at /temp/tasmax_day_BCSD_historical_r1i1p1_inmcm4_1971.nc\n"
     ]
    }
   ],
   "source": [
    "tasmax_filenames, tasmax_datasets, tasmax_current_year_stack = download_and_stack(year, variable=vars[0])\n",
    "tasmin_filenames, tasmin_datasets, tasmin_current_year_stack = download_and_stack(year, variable=vars[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tasavg = da.stack((tasmax_current_year_stack, tasmin_current_year_stack), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_np = np.mean(tasavg, axis= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 365, 720, 1440)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://scheduler:8786\n",
       "  <li><b>Dashboard: </b><a href='http://scheduler:8787' target='_blank'>http://scheduler:8787</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>16.81 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://172.21.0.4:8786' processes=1 cores=4>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
