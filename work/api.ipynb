{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": true,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import os\n",
    "import itertools\n",
    "import netCDF4\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "from dask import delayed\n",
    "import dask.array as da\n",
    "from dask.distributed import Client\n",
    "import glob\n",
    "import tempfile\n",
    "import subprocess\n",
    "import datetime, time\n",
    "from urllib import request\n",
    "from multiprocessing import Pool\n",
    "import json\n",
    "import gc\n",
    "\n",
    "download_location = '/temp'\n",
    "# data_url = 'http://nasanex.s3.amazonaws.com'\n",
    "data_url = 'http://172.19.0.1:8081'\n",
    "max_download_attempts = 5\n",
    "client = Client('scheduler:8786')\n",
    "#\n",
    "storage_client = storage.Client.from_service_account_json('/home/jovyan/work/credentials.json')\n",
    "bucket = storage_client.get_bucket('nexgddp')\n",
    "\n",
    "\n",
    "# Actual processing\n",
    "# We load the temperature baseline from a numpy array in disk\n",
    "baseline = da.from_array(np.load('/home/jovyan/work/baseline_tasmax_99p.npy'), chunks = (144, 144))\n",
    "\n",
    "# And define the functions to be applied over each dataset\n",
    "# This if for a single year, either one of the variables or the\n",
    "# tasavg stack, which would be calculated on-the-fly\n",
    "\n",
    "# Heating Degree Days - in C, transformation to F should not be problematic\n",
    "def hdd(a, axis):\n",
    "    a_to_baseline = 291.483 - a\n",
    "    masked = ma.masked_where(a_to_baseline <= 0, a_to_baseline)\n",
    "    intermediate_matrix = ma.filled(masked, fill_value = 0)\n",
    "    result = np.sum(intermediate_matrix, axis = 0)\n",
    "    return result\n",
    "\n",
    "# Cooling degree days\n",
    "def cdd(a, axis):\n",
    "    a_to_baseline = 291.483 - a\n",
    "    a_to_baseline[a_to_baseline < -10000] = 0\n",
    "    masked = ma.masked_where(a_to_baseline >= 0, a_to_baseline)\n",
    "    intermediate_matrix = ma.filled(masked, fill_value = 0)\n",
    "    result = np.sum(np.abs(intermediate_matrix), axis = 0)\n",
    "    return result\n",
    "\n",
    "# Number of days of the year with tasmax > 99 percentile from baseline 1971-2000\n",
    "def extreme_heat(a, axis):\n",
    "    a_to_baseline = a - baseline\n",
    "    masked = ma.masked_where(a_to_baseline <= 0, a_to_baseline)\n",
    "    intermediate_matrix = ma.filled(masked, fill_value = 0)\n",
    "    result = np.count_nonzero(intermediate_matrix, axis = axis)\n",
    "    return result\n",
    "\n",
    "# Helper function, not to be applied directly on the worker\n",
    "def longest_streak(diff):\n",
    "    result = 0\n",
    "    try:\n",
    "        result =  np.amax(\n",
    "            np.array(np.where(diff < 0)) - np.array(np.where(diff > 0))\n",
    "        )\n",
    "    except ValueError:\n",
    "        #raised if empty\n",
    "        result = 0\n",
    "    return result\n",
    "\n",
    "# Longest streak of days over freezing temperature (tasmin)\n",
    "def frost_free_season(a, axis):\n",
    "    # First, dealing with the first matrix\n",
    "    frost_days_matrix = (a > 273.15) * 1\n",
    "    # We pad it with zeroes at the ends of the designed axis\n",
    "    zeros_shape = list(a.shape)\n",
    "    del zeros_shape[axis]\n",
    "    zeros_matrix = np.expand_dims(np.zeros(zeros_shape), axis = axis)\n",
    "    concat_matrix = np.concatenate((zeros_matrix, frost_days_matrix, zeros_matrix))\n",
    "    # We calculate the deltas along an axis\n",
    "    diff = np.diff(concat_matrix, axis = axis)\n",
    "    # And get the longest streak from there --\n",
    "    # apply along axis is far from ideal, but\n",
    "    # np.where doesn't operate over axes, so we have to iterate\n",
    "    result = np.apply_along_axis(longest_streak, axis, diff)\n",
    "    return result\n",
    "# Downloading files\n",
    "def get_urls(year, model, scenario):\n",
    "    urls = []\n",
    "    for var in ['tasmax', 'tasmin']:\n",
    "        # prefix_filename = '/'.join([data_url, 'NEX-GDDP', 'BCSD', scenario, 'day', 'atmos', var, 'r1i1p1', 'v1.0'])\n",
    "        prefix_filename = data_url\n",
    "        filename = '_'.join([var, 'day', 'BCSD', scenario, 'r1i1p1', model, str(year) + '.nc'])\n",
    "        urls.append('/'.join([prefix_filename, filename]))\n",
    "    return urls\n",
    "\n",
    "def download(year, model, scenario):\n",
    "    tasmax_url, tasmin_url = get_urls(year, model, scenario)\n",
    "    urls = [tasmax_url, tasmin_url]\n",
    "    filenames = list(map(lambda url: '/temp/' + url.split('/')[-1],  urls))\n",
    "    pool = Pool()\n",
    "    filenames = pool.map(download_file, urls)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return filenames\n",
    "\n",
    "def download_file(url):\n",
    "    attempts = 0\n",
    "    success = False\n",
    "    filename = \"\"\n",
    "    while attempts < max_download_attempts and not success:\n",
    "        time.sleep(2 ** attempts)\n",
    "        filename = '/'.join([download_location, str(url.split('/')[-1])])\n",
    "        u = request.urlopen(url)\n",
    "        f = open(filename, 'wb')\n",
    "        f.write(u.read())\n",
    "        f.close()\n",
    "        success = True\n",
    "        break\n",
    "    return filename\n",
    "\n",
    "def download_and_process(year, model, scenario):\n",
    "    filenames = download(year, model, scenario)\n",
    "    da_arrays = [\n",
    "              da.from_array(netCDF4.Dataset(filenames[0])['tasmax'], chunks = (366, 144, 144)),\n",
    "              da.from_array(netCDF4.Dataset(filenames[1])['tasmin'], chunks = (366, 144, 144))\n",
    "    ]\n",
    "\n",
    "    base_stack = da.stack(da_arrays)\n",
    "    tasmax_stack = da_arrays[0]\n",
    "    tasmin_stack = da_arrays[1]\n",
    "\n",
    "    tasavg = np.mean(base_stack, axis = 0)\n",
    "    avg_tasmin = np.mean(tasmin_stack, axis = 0).compute()\n",
    "    avg_tasmax = np.mean(tasmax_stack, axis = 0).compute()\n",
    "    avg_tasavg = np.mean(tasavg, axis = 0).compute()\n",
    "\n",
    "    avg_tasmin[avg_tasmin > 1000] = -1\n",
    "    avg_tasmax[avg_tasmax > 1000] = -1\n",
    "    avg_tasavg[avg_tasavg > 1000] = -1\n",
    "\n",
    "    hdds = delayed(hdd)(tasavg, axis = 0).compute()\n",
    "    cdds = delayed(cdd)(tasavg, axis = 0).compute()\n",
    "    ffs = delayed(frost_free_season)(tasmin_stack, axis = 0).compute()\n",
    "    xs = delayed(extreme_heat)(tasmax_stack, axis = 0).compute()\n",
    "\n",
    "    results = np.stack((\n",
    "            avg_tasmax,\n",
    "            avg_tasmin,\n",
    "            avg_tasavg,\n",
    "            hdds,\n",
    "            cdds,\n",
    "            ffs,\n",
    "            xs\n",
    "    ))\n",
    "    output_filename = f'{year}_{model}_processed_temperatures.npy'\n",
    "    np.save('/temp/' + output_filename, results)\n",
    "    blob = bucket.blob(output_filename)\n",
    "    blob.upload_from_filename('/temp/' + output_filename)\n",
    "    \n",
    "    client.cancel(base_stack)\n",
    "    del base_stack\n",
    "    del tasmax_stack\n",
    "    del tasmin_stack\n",
    "    del tasavg\n",
    "    del avg_tasmin\n",
    "    del avg_tasmax\n",
    "    del avg_tasavg\n",
    "    del hdds\n",
    "    del cdds\n",
    "    del ffs\n",
    "    del xs\n",
    "    gc.collect()\n",
    "    client.restart()\n",
    "    return output_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# GET /process/:year/:model/:scenario\n",
    "req = json.loads(REQUEST)\n",
    "year = int(req['path']['year'])\n",
    "model = req['path']['model']\n",
    "scenario = req['path']['scenario']\n",
    "\n",
    "for ncdf in glob.glob('/temp/*.nc*'):\n",
    "    os.remove(ncdf)\n",
    "\n",
    "result = download_and_process(year, model, scenario)\n",
    "print({'output': result})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "name": "api.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
